{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db81a50-bfd1-4fa8-be5b-cc81c0814c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e59d4a65-6227-4a6a-a8fd-7277b6378e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "COLAB = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if COLAB: # running on Colab\n",
    "    \n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    gdrive_path = '/content/drive//MyDrive/DL4CV-2022/project-I/'\n",
    "    sys.path.append(gdrive_path)\n",
    "\n",
    "else:\n",
    "    path = 'data'\n",
    "    \n",
    "import utils.helpers as utils\n",
    "import loader.gtsrb_data as dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8abfcf83-83fa-4236-81a1-0e92d4d89196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(annotations_file='data/Final_Training/Annotations', batch_size=50, data_dir_test='data/Final_Test', data_dir_train='data/Final_Training/Images', data_dir_val='data/Final_Validation', decay_rate=0.97, gpu_mem=0.666, init_from=None, learning_rate=0.002, log_dir='logs', num_epochs=5, save_dir='save', save_every=1000)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data_dir_train', type=str, default='data/Final_Training/Images',\n",
    "                   help='data directory containing training image class folders')\n",
    "parser.add_argument('--data_dir_test', type=str, default='data/Final_Test',\n",
    "                   help='data directory containing test images')\n",
    "parser.add_argument('--annotations_file', type=str, default='data/Final_Training/Annotations',\n",
    "                   help='data directory containing class annotations file')\n",
    "parser.add_argument('--data_dir_val', type=str, default='data/Final_Validation',\n",
    "                   help='data directory containing validation images')\n",
    "parser.add_argument('--log_dir', type=str, default='logs',\n",
    "                   help='directory containing logs')\n",
    "parser.add_argument('--save_dir', type=str, default='save',\n",
    "                   help='directory to store checkpointed models')\n",
    "parser.add_argument('--batch_size', type=int, default=50,\n",
    "                   help='minibatch size')\n",
    "parser.add_argument('--num_epochs', type=int, default=5,\n",
    "                   help='number of epochs')\n",
    "parser.add_argument('--save_every', type=int, default=1000,\n",
    "                   help='save frequency')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.002,\n",
    "                   help='learning rate')\n",
    "parser.add_argument('--decay_rate', type=float, default=0.97,\n",
    "                   help='decay rate for rmsprop')\n",
    "parser.add_argument('--gpu_mem', type=float, default=0.666,\n",
    "                   help='%% of gpu memory to be allocated to this process. Default is 66.6%%')\n",
    "parser.add_argument('--init_from', type=str, default=None,\n",
    "                   help=\"\"\"continue training from saved model at this path. Path must contain files saved by previous training process:\n",
    "                        'config.pkl'        : configuration;\n",
    "                        'words_vocab.pkl'   : vocabulary definitions;\n",
    "                        'checkpoint'        : paths to model file(s) (created by tf).\n",
    "                                              Note: this file contains absolute paths, be careful when moving files around;\n",
    "                        'model.ckpt-*'      : file(s) with model definition (created by tf)\n",
    "                    \"\"\")\n",
    "args = parser.parse_args(args=[])\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebca091b-6bbf-4a1b-aaec-ef0693a769d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform=TRANSFORM_IMG\n",
    "transform=None\n",
    "\n",
    "if COLAB:\n",
    "    TRAIN_DATA_PATH = gdrive_path+args.data_dir_train\n",
    "    VAL_DATA_PATH = gdrive_path+args.data_dir_val\n",
    "    TEST_DATA_PATH = gdrive_path+args.data_dir_test\n",
    "    print(gdrive_path+args.data_dir_test)\n",
    "    print(gdrive_path+args.annotations_file)\n",
    "\n",
    "else:\n",
    "    TRAIN_DATA_PATH = os.getcwd()+'/'+args.data_dir_train\n",
    "    VAL_DATA_PATH = os.getcwd()+'/'+args.data_dir_val\n",
    "    TEST_DATA_PATH = os.getcwd()+'/'+args.data_dir_test\n",
    "    \n",
    "BATCH_SIZE = args.batch_size\n",
    "EPOCHS = args.num_epochs\n",
    "BATCH_SIZE = args.batch_size\n",
    "LEARNING_RATE = args.learning_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abff6254-15ea-4d9c-88f9-aa442cbba976",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data        = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, transform=None)\n",
    "train_data_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)\n",
    "test_data         = torchvision.datasets.ImageFolder(root=TEST_DATA_PATH, transform=None)\n",
    "test_data_loader  = data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_data          = torchvision.datasets.ImageFolder(root=VAL_DATA_PATH, transform=None)\n",
    "val_data_loader   = data.DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9785237-2a4a-438e-8fde-47e45b4ad2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39209\n",
      "12630\n",
      "3870\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef4c9c6-7229-412b-9000-d481c65d6505",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_dict = train_data.class_to_idx\n",
    "val_class_dict = val_data.class_to_idx\n",
    "test_class_dict = test_data.class_to_idx # A 'single' class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b319ddb-7cfe-4d06-8221-785813b19ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
