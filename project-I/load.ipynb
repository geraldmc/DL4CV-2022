{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db81a50-bfd1-4fa8-be5b-cc81c0814c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e59d4a65-6227-4a6a-a8fd-7277b6378e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "COLAB = 'google.colab' in str(get_ipython())\n",
    "TRANSFORMS = True\n",
    "HAS_GPU = torch.cuda.is_available()\n",
    "\n",
    "if COLAB: # running on Colab\n",
    "    \n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    gdrive_path = '/content/drive//MyDrive/DL4CV-2022/project-I/'\n",
    "    sys.path.append(gdrive_path)\n",
    "    \n",
    "    if HAS_GPU:\n",
    "        print(\"Using GPU\")\n",
    "else:\n",
    "    path = 'data'\n",
    "    HAS_GPU = False\n",
    "    print(\"Using CPU\")\n",
    "    \n",
    "import utils.helpers as utils\n",
    "import loader.gtsrb_data as dataset\n",
    "\n",
    "# If we have cuda running then accomodate these datatype.\n",
    "FloatTensor = torch.cuda.FloatTensor if HAS_GPU else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if HAS_GPU else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if HAS_GPU else torch.ByteTensor\n",
    "Tensor = FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8abfcf83-83fa-4236-81a1-0e92d4d89196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(annotations_file='data/Final_Training/Annotations', batch_size=50, data_dir_test='data/Final_Test', data_dir_train='data/Final_Training/Images', data_dir_val='data/Final_Validation', decay_rate=0.97, gpu_mem=0.666, init_from=None, learning_rate=0.0001, log_dir='logs', log_interval=10, num_epochs=5, save_dir='save', save_every=1000, seed=1)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Load and train arguments\n",
    "parser.add_argument('--data_dir_train', type=str, default='data/Final_Training/Images',\n",
    "                   help='data directory containing training image class folders')\n",
    "parser.add_argument('--data_dir_test', type=str, default='data/Final_Test',\n",
    "                   help='data directory containing test images')\n",
    "parser.add_argument('--annotations_file', type=str, default='data/Final_Training/Annotations',\n",
    "                   help='data directory containing class annotations file')\n",
    "parser.add_argument('--data_dir_val', type=str, default='data/Final_Validation',\n",
    "                   help='data directory containing validation images')\n",
    "parser.add_argument('--log_dir', type=str, default='logs',\n",
    "                   help='directory containing logs')\n",
    "parser.add_argument('--save_dir', type=str, default='save',\n",
    "                   help='directory to store checkpointed models')\n",
    "parser.add_argument('--batch_size', type=int, default=50,\n",
    "                   help='input batch size for training')\n",
    "parser.add_argument('--num_epochs', type=int, default=5,\n",
    "                   help='number of epochs to train')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.0001,\n",
    "                    help='learning rate (default: 0.0001)')\n",
    "parser.add_argument('--seed', type=int, default=1,\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10,\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--save_every', type=int, default=1000,\n",
    "                   help='save frequency')\n",
    "parser.add_argument('--decay_rate', type=float, default=0.97,\n",
    "                   help='decay rate for rmsprop')\n",
    "parser.add_argument('--gpu_mem', type=float, default=0.666,\n",
    "                   help='%% of gpu memory to be allocated to this process. Default is 66.6%%')\n",
    "parser.add_argument('--init_from', type=str, default=None,\n",
    "                   help=\"\"\"continue training from saved model at this path. Path must contain files saved by previous training process:\n",
    "                        'config.pkl'        : configuration;\n",
    "                        'words_vocab.pkl'   : vocabulary definitions;\n",
    "                        'checkpoint'        : paths to model file(s) (created by tf).\n",
    "                                              Note: this file contains absolute paths, be careful when moving files around;\n",
    "                        'model.ckpt-*'      : file(s) with model definition (created by tf)\n",
    "                    \"\"\")\n",
    "args = parser.parse_args(args=[])\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebca091b-6bbf-4a1b-aaec-ef0693a769d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform=TRANSFORM_IMG\n",
    "\n",
    "if COLAB:\n",
    "    TRAIN_DATA_PATH = gdrive_path+args.data_dir_train\n",
    "    VAL_DATA_PATH = gdrive_path+args.data_dir_val\n",
    "    TEST_DATA_PATH = gdrive_path+args.data_dir_test\n",
    "    print(gdrive_path+args.data_dir_test)\n",
    "    print(gdrive_path+args.annotations_file)\n",
    "\n",
    "else:\n",
    "    TRAIN_DATA_PATH = os.getcwd()+'/'+args.data_dir_train\n",
    "    VAL_DATA_PATH = os.getcwd()+'/'+args.data_dir_val\n",
    "    TEST_DATA_PATH = os.getcwd()+'/'+args.data_dir_test\n",
    "    \n",
    "BATCH_SIZE = args.batch_size\n",
    "EPOCHS = args.num_epochs\n",
    "BATCH_SIZE = args.batch_size\n",
    "LEARNING_RATE = args.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abff6254-15ea-4d9c-88f9-aa442cbba976",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRANSFORMS:\n",
    "    from utils.loader import transforms\n",
    "\n",
    "\n",
    "    # Apply data transformation to augment training imageset.\n",
    "    train_loader = torch.utils.data.DataLoader(datasets.ImageFolder(TRAIN_DATA_PATH,\n",
    "                                                                     transform=transforms.data_transforms), \n",
    "                                               batch_size=args.batch_size, \n",
    "                                               shuffle=True, num_workers=2, \n",
    "                                               pin_memory=HAS_GPU)\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(datasets.ImageFolder(VAL_DATA_PATH,\n",
    "                                                                  transform=transforms.data_transforms),\n",
    "                                             batch_size=args.batch_size, \n",
    "                                             shuffle=False, num_workers=2, \n",
    "                                             pin_memory=HAS_GPU)\n",
    "    \n",
    "    # Apply data transformations to augment the training imageset.\n",
    "   # train_loader = torch.utils.data.DataLoader(\n",
    "   #     torch.utils.data.ConcatDataset([torchvision.datasets.ImageFolder(TRAIN_DATA_PATH,\n",
    "   #     transform=transforms.data_transforms),torchvision.datasets.ImageFolder(TRAIN_DATA_PATH,\n",
    "   #     transform=transforms.data_jitter_contrast),torchvision.datasets.ImageFolder(TRAIN_DATA_PATH,\n",
    "   #     transform=transforms.data_grayscale),torchvision.datasets.ImageFolder(TRAIN_DATA_PATH,\n",
    "   #     transform=transforms.data_translate)]), \n",
    "   #         batch_size=args.batch_size, \n",
    "   #         shuffle=True, num_workers=2, \n",
    "   #         pin_memory=HAS_GPU)\n",
    "\n",
    "else: # In this case train=39209, test=12630, val=3870\n",
    "    train_data        = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, transform=None)\n",
    "    train_data_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)\n",
    "    test_data         = torchvision.datasets.ImageFolder(root=TEST_DATA_PATH, transform=None)\n",
    "    test_data_loader  = data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_data          = torchvision.datasets.ImageFolder(root=VAL_DATA_PATH, transform=None)\n",
    "    val_data_loader   = data.DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)\n",
    "    \n",
    "# Order: data_transforms, data_jitter_contrast, data_grayscale, data_translate  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9785237-2a4a-438e-8fde-47e45b4ad2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39209\n",
      "12630\n",
      "3870\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef4c9c6-7229-412b-9000-d481c65d6505",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_dict = train_data.class_to_idx\n",
    "val_class_dict = val_data.class_to_idx\n",
    "test_class_dict = test_data.class_to_idx # A 'single' class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61a83a28-c008-403b-8c9c-26fd0d053f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network and Optimizer\n",
    "from model.models import Net as NN\n",
    "model = NN()\n",
    "\n",
    "if HAS_GPU:\n",
    "    model.cuda()\n",
    "    \n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad,\n",
    "                              model.parameters()),\n",
    "                              lr=args.learning_rate)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                 'min',\n",
    "                                                 patience=5,\n",
    "                                                 factor=0.5,\n",
    "                                                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c05cef4-43cc-43af-b82b-59fdbbcf365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    training_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        if use_gpu:\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        max_index = output.max(dim = 1)[1]\n",
    "        correct += (max_index == target).sum()\n",
    "        training_loss += loss\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss per example: {:.6f}\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader), loss.data.item()/(args.batch_size * args.log_interval),\n",
    "                        loss.data.item()))\n",
    "            print('\\nTraining set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "                training_loss / len(train_loader.dataset), correct, len(train_loader.dataset),\n",
    "                100. * correct / len(train_loader.dataset)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292c2c5e-2636-414b-bf0a-7a2f181e8b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
