{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db81a50-bfd1-4fa8-be5b-cc81c0814c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e59d4a65-6227-4a6a-a8fd-7277b6378e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "COLAB = 'google.colab' in str(get_ipython())\n",
    "TRANSFORMS = True\n",
    "HAS_GPU = torch.cuda.is_available()\n",
    "\n",
    "if COLAB: # running on Colab\n",
    "    \n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    gdrive_path = '/content/drive//MyDrive/DL4CV-2022/project-I/'\n",
    "    sys.path.append(gdrive_path)\n",
    "\n",
    "    zip_path_train = gdrive_path + 'data/Final_Training.zip'\n",
    "    zip_path_val = gdrive_path + 'data/Final_Validation.zip'\n",
    "    !unzip -q \"{zip_path_train}\"\n",
    "    !unzip -q \"{zip_path_val}\"\n",
    "    \n",
    "    if HAS_GPU:\n",
    "        print(\"Using GPU\")\n",
    "else:\n",
    "    path = 'data'\n",
    "    HAS_GPU = False\n",
    "    print(\"Using CPU\")\n",
    "    \n",
    "import utils.helpers as utils\n",
    "import loader.gtsrb_data as dataset\n",
    "\n",
    "# If we run cuda then accomodate these datatype.\n",
    "FloatTensor = torch.cuda.FloatTensor if HAS_GPU else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if HAS_GPU else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if HAS_GPU else torch.ByteTensor\n",
    "Tensor = FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a8a0d-345a-4418-89ba-cf282ca8adf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "  !ls /content/Final_Training/Images\n",
    "  !ls /content/Final_Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8abfcf83-83fa-4236-81a1-0e92d4d89196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(annotations_file='data/Final_Training/Annotations', batch_size=50, data_dir_test='data/Final_Test', data_dir_train='data/Final_Training/Images', data_dir_val='data/Final_Validation', decay_rate=0.97, gpu_mem=0.666, init_from=None, learning_rate=0.0001, log_dir='logs', log_interval=100, num_epochs=100, save_dir='save', save_every=1000, seed=1)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Load and train arguments\n",
    "parser.add_argument('--data_dir_train', type=str, default='/content/Final_Training/Images',\n",
    "                   help='data directory containing training image class folders')\n",
    "parser.add_argument('--data_dir_test', type=str, default='data/Final_Test',\n",
    "                   help='data directory containing test images')\n",
    "parser.add_argument('--annotations_file', type=str, default='/content/Final_Training/Annotations',\n",
    "                   help='data directory containing class annotations file')\n",
    "parser.add_argument('--data_dir_val', type=str, default='/content/Final_Validation',\n",
    "                   help='data directory containing validation images')\n",
    "parser.add_argument('--log_dir', type=str, default='logs',\n",
    "                   help='directory containing logs')\n",
    "parser.add_argument('--save_dir', type=str, default='save',\n",
    "                   help='directory to store checkpointed models')\n",
    "parser.add_argument('--batch_size', type=int, default=50,\n",
    "                   help='input batch size for training')\n",
    "parser.add_argument('--num_epochs', type=int, default=5,\n",
    "                   help='number of epochs to train')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.0001,\n",
    "                    help='learning rate (default: 0.0001)')\n",
    "parser.add_argument('--seed', type=int, default=1,\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=100,\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--save_every', type=int, default=1000,\n",
    "                   help='save frequency')\n",
    "parser.add_argument('--decay_rate', type=float, default=0.97,\n",
    "                   help='decay rate for rmsprop')\n",
    "parser.add_argument('--gpu_mem', type=float, default=0.666,\n",
    "                   help='%% of gpu memory to be allocated to this process. Default is 66.6%%')\n",
    "parser.add_argument('--init_from', type=str, default=None,\n",
    "                   help=\"\"\"continue training from saved model at this path. Path must contain files saved by previous training process:\n",
    "                        'config.pkl'        : configuration;\n",
    "                        'words_vocab.pkl'   : vocabulary definitions;\n",
    "                        'checkpoint'        : paths to model file(s) (created by tf).\n",
    "                                              Note: this file contains absolute paths, be careful when moving files around;\n",
    "                        'model.ckpt-*'      : file(s) with model definition (created by tf)\n",
    "                    \"\"\")\n",
    "args = parser.parse_args(args=[])\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebca091b-6bbf-4a1b-aaec-ef0693a769d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform=TRANSFORM_IMG\n",
    "\n",
    "if COLAB:\n",
    "    TRAIN_DATA_PATH = args.data_dir_train\n",
    "    VAL_DATA_PATH = args.data_dir_val\n",
    "    TEST_DATA_PATH = gdrive_path+args.data_dir_test\n",
    "    print(args.data_dir_train)\n",
    "    print(args.data_dir_val)\n",
    "\n",
    "else:\n",
    "    TRAIN_DATA_PATH = os.getcwd()+'/'+args.data_dir_train\n",
    "    VAL_DATA_PATH = os.getcwd()+'/'+args.data_dir_val\n",
    "    TEST_DATA_PATH = os.getcwd()+'/'+args.data_dir_test\n",
    "    \n",
    "BATCH_SIZE = args.batch_size\n",
    "EPOCHS = args.num_epochs\n",
    "BATCH_SIZE = args.batch_size\n",
    "LEARNING_RATE = args.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abff6254-15ea-4d9c-88f9-aa442cbba976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader import transforms as tfs\n",
    "\n",
    "if TRANSFORMS:\n",
    "\n",
    "    # Apply data transformation to augment training imageset.\n",
    "    train_loader = torch.utils.data.DataLoader(datasets.ImageFolder(\n",
    "                                                TRAIN_DATA_PATH,\n",
    "                                                transform=tfs.data_transforms), \n",
    "                                                batch_size=args.batch_size, \n",
    "                                                shuffle=True, num_workers=2, \n",
    "                                                pin_memory=HAS_GPU)\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(datasets.ImageFolder(\n",
    "                                                VAL_DATA_PATH,\n",
    "                                                transform=tfs.data_transforms),\n",
    "                                                batch_size=args.batch_size, \n",
    "                                                shuffle=False, num_workers=2, \n",
    "                                                pin_memory=HAS_GPU)\n",
    "    \n",
    "    # Apply data transformations to augment the training imageset.\n",
    "   # train_loader = torch.utils.data.DataLoader(\n",
    "   #     torch.utils.data.ConcatDataset([torchvision.datasets.ImageFolder(TRAIN_DATA_PATH,\n",
    "   #     transform=transforms.data_transforms),torchvision.datasets.ImageFolder(TRAIN_DATA_PATH,\n",
    "   #     transform=transforms.data_jitter_contrast),torchvision.datasets.ImageFolder(TRAIN_DATA_PATH,\n",
    "   #     transform=transforms.data_grayscale),torchvision.datasets.ImageFolder(TRAIN_DATA_PATH,\n",
    "   #     transform=transforms.data_translate)]), \n",
    "   #         batch_size=args.batch_size, \n",
    "   #         shuffle=True, num_workers=2, \n",
    "   #         pin_memory=HAS_GPU)\n",
    "\n",
    "else: # In this case train=39209, test=12630, val=3870\n",
    "    train_data        = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, \n",
    "                                                         transform=tfs.data_transforms)\n",
    "    train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)\n",
    "    test_data         = torchvision.datasets.ImageFolder(root=TEST_DATA_PATH, \n",
    "                                                         transform=tfs.data_transforms)\n",
    "    test_loader  = data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_data          = torchvision.datasets.ImageFolder(root=VAL_DATA_PATH, \n",
    "                                                         transform=tfs.data_transforms)\n",
    "    val_loader   = data.DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)\n",
    "    \n",
    "# Order: data_transforms, data_jitter_contrast, data_grayscale, data_translate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9785237-2a4a-438e-8fde-47e45b4ad2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39209\n",
      "12630\n",
      "3870\n"
     ]
    }
   ],
   "source": [
    "if COLAB:\n",
    "  print(len(train_loader))\n",
    "  print(len(val_loader))\n",
    "else:\n",
    "  print(len(train_data))\n",
    "  print(len(test_data))\n",
    "  print(len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef4c9c6-7229-412b-9000-d481c65d6505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network and Optimizer\n",
    "from model.models import Net as NN\n",
    "model = NN()\n",
    "\n",
    "if HAS_GPU:\n",
    "    model.cuda()\n",
    "    \n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad,\n",
    "                              model.parameters()),\n",
    "                              lr=args.learning_rate)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                 'min',\n",
    "                                                 patience=5,\n",
    "                                                 factor=0.5,\n",
    "                                                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c05cef4-43cc-43af-b82b-59fdbbcf365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    training_loss = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        if HAS_GPU:\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        max_index = output.max(dim = 1)[1]\n",
    "        correct += (max_index == target).sum()\n",
    "        training_loss += loss\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss per example: {:.6f}\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader), loss.data.item()/(args.batch_size * args.log_interval),\n",
    "                        loss.data.item()))\n",
    "            print('\\nTraining set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "                training_loss / len(train_loader.dataset), correct, len(train_loader.dataset),\n",
    "                100. * correct / len(train_loader.dataset)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "292c2c5e-2636-414b-bf0a-7a2f181e8b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation():\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in val_loader:\n",
    "        with torch.no_grad():\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            if HAS_GPU:\n",
    "                data = data.cuda()\n",
    "                target = target.cuda()\n",
    "            output = model(data)\n",
    "            validation_loss += F.nll_loss(output, target, size_average=False).data.item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    validation_loss /= len(val_loader.dataset)\n",
    "    scheduler.step(np.around(validation_loss,2))\n",
    "    \n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        validation_loss, correct, len(val_loader.dataset),\n",
    "        100. * correct / len(val_loader.dataset)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddafcd9-6772-4350-afb8-f25e638968ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/39209 (0%)]\tLoss per example: 0.000756\tLoss: 3.780284\n",
      "\n",
      "Training set: Average loss: 0.0001, Accuracy: 0/39209 (0%)\n",
      "\n",
      "Train Epoch: 1 [5000/39209 (13%)]\tLoss per example: 0.000663\tLoss: 3.313797\n",
      "\n",
      "Training set: Average loss: 0.0092, Accuracy: 404/39209 (1%)\n",
      "\n",
      "Train Epoch: 1 [10000/39209 (25%)]\tLoss per example: 0.000604\tLoss: 3.020405\n",
      "\n",
      "Training set: Average loss: 0.0173, Accuracy: 1273/39209 (3%)\n",
      "\n",
      "Train Epoch: 1 [15000/39209 (38%)]\tLoss per example: 0.000491\tLoss: 2.455574\n",
      "\n",
      "Training set: Average loss: 0.0245, Accuracy: 2564/39209 (7%)\n",
      "\n",
      "Train Epoch: 1 [20000/39209 (51%)]\tLoss per example: 0.000493\tLoss: 2.463892\n",
      "\n",
      "Training set: Average loss: 0.0309, Accuracy: 4181/39209 (11%)\n",
      "\n",
      "Train Epoch: 1 [25000/39209 (64%)]\tLoss per example: 0.000425\tLoss: 2.123121\n",
      "\n",
      "Training set: Average loss: 0.0364, Accuracy: 6198/39209 (16%)\n",
      "\n",
      "Train Epoch: 1 [30000/39209 (76%)]\tLoss per example: 0.000320\tLoss: 1.597590\n",
      "\n",
      "Training set: Average loss: 0.0412, Accuracy: 8549/39209 (22%)\n",
      "\n",
      "Train Epoch: 1 [35000/39209 (89%)]\tLoss per example: 0.000272\tLoss: 1.360460\n",
      "\n",
      "Training set: Average loss: 0.0453, Accuracy: 11254/39209 (29%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: dlopen(/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/image.so, 0x0006): symbol not found in flat namespace '__ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: dlopen(/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/image.so, 0x0006): symbol not found in flat namespace '__ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: dlopen(/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/image.so, 0x0006): symbol not found in flat namespace '__ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: dlopen(/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/image.so, 0x0006): symbol not found in flat namespace '__ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 1.6887, Accuracy: 2130/3870 (55%)\n",
      "\n",
      "Train Epoch: 2 [0/39209 (0%)]\tLoss per example: 0.000267\tLoss: 1.336278\n",
      "\n",
      "Training set: Average loss: 0.0000, Accuracy: 29/39209 (0%)\n",
      "\n",
      "Train Epoch: 2 [5000/39209 (13%)]\tLoss per example: 0.000258\tLoss: 1.288401\n",
      "\n",
      "Training set: Average loss: 0.0031, Accuracy: 3326/39209 (8%)\n",
      "\n",
      "Train Epoch: 2 [10000/39209 (25%)]\tLoss per example: 0.000204\tLoss: 1.020322\n",
      "\n",
      "Training set: Average loss: 0.0057, Accuracy: 6891/39209 (18%)\n",
      "\n",
      "Train Epoch: 2 [15000/39209 (38%)]\tLoss per example: 0.000167\tLoss: 0.837024\n",
      "\n",
      "Training set: Average loss: 0.0079, Accuracy: 10701/39209 (27%)\n",
      "\n",
      "Train Epoch: 2 [20000/39209 (51%)]\tLoss per example: 0.000137\tLoss: 0.683697\n",
      "\n",
      "Training set: Average loss: 0.0097, Accuracy: 14700/39209 (37%)\n",
      "\n",
      "Train Epoch: 2 [25000/39209 (64%)]\tLoss per example: 0.000095\tLoss: 0.474875\n",
      "\n",
      "Training set: Average loss: 0.0113, Accuracy: 18908/39209 (48%)\n",
      "\n",
      "Train Epoch: 2 [30000/39209 (76%)]\tLoss per example: 0.000117\tLoss: 0.586917\n",
      "\n",
      "Training set: Average loss: 0.0127, Accuracy: 23131/39209 (59%)\n",
      "\n",
      "Train Epoch: 2 [35000/39209 (89%)]\tLoss per example: 0.000079\tLoss: 0.395829\n",
      "\n",
      "Training set: Average loss: 0.0140, Accuracy: 27491/39209 (70%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: dlopen(/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/image.so, 0x0006): symbol not found in flat namespace '__ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: dlopen(/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/image.so, 0x0006): symbol not found in flat namespace '__ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: dlopen(/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/image.so, 0x0006): symbol not found in flat namespace '__ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: dlopen(/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/image.so, 0x0006): symbol not found in flat namespace '__ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 0.2956, Accuracy: 3617/3870 (93%)\n",
      "\n",
      "Train Epoch: 3 [0/39209 (0%)]\tLoss per example: 0.000080\tLoss: 0.398937\n",
      "\n",
      "Training set: Average loss: 0.0000, Accuracy: 44/39209 (0%)\n",
      "\n",
      "Train Epoch: 3 [5000/39209 (13%)]\tLoss per example: 0.000056\tLoss: 0.280790\n",
      "\n",
      "Training set: Average loss: 0.0010, Accuracy: 4546/39209 (12%)\n",
      "\n",
      "Train Epoch: 3 [10000/39209 (25%)]\tLoss per example: 0.000085\tLoss: 0.425730\n",
      "\n",
      "Training set: Average loss: 0.0019, Accuracy: 9095/39209 (23%)\n",
      "\n",
      "Train Epoch: 3 [15000/39209 (38%)]\tLoss per example: 0.000034\tLoss: 0.170600\n",
      "\n",
      "Training set: Average loss: 0.0027, Accuracy: 13684/39209 (35%)\n",
      "\n",
      "Train Epoch: 3 [20000/39209 (51%)]\tLoss per example: 0.000065\tLoss: 0.326387\n",
      "\n",
      "Training set: Average loss: 0.0035, Accuracy: 18320/39209 (47%)\n",
      "\n",
      "Train Epoch: 3 [25000/39209 (64%)]\tLoss per example: 0.000037\tLoss: 0.185411\n",
      "\n",
      "Training set: Average loss: 0.0041, Accuracy: 22992/39209 (59%)\n",
      "\n",
      "Train Epoch: 3 [30000/39209 (76%)]\tLoss per example: 0.000062\tLoss: 0.307867\n",
      "\n",
      "Training set: Average loss: 0.0047, Accuracy: 27699/39209 (71%)\n",
      "\n",
      "Train Epoch: 3 [35000/39209 (89%)]\tLoss per example: 0.000040\tLoss: 0.201209\n",
      "\n",
      "Training set: Average loss: 0.0053, Accuracy: 32373/39209 (83%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.num_epochs + 1):\n",
    "    train(epoch)\n",
    "    validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871b4e85-0c8c-4ebe-8185-ff2189e2a975",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
