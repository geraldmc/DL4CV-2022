{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db81a50-bfd1-4fa8-be5b-cc81c0814c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061ab42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e59d4a65-6227-4a6a-a8fd-7277b6378e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "COLAB = 'google.colab' in str(get_ipython())\n",
    "HAS_GPU = torch.cuda.is_available()\n",
    "is_local = not COLAB\n",
    "\n",
    "if COLAB: # running on Colab\n",
    "    \n",
    "    from google.colab import drive\n",
    "    drive.flush_and_unmount()\n",
    "    \n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    gdrive_path = '/content/drive//MyDrive/DL4CV-2022/project-I/'\n",
    "    sys.path.append(gdrive_path)\n",
    "\n",
    "    zip_path_train = gdrive_path + 'data/Final_Training.zip'\n",
    "    zip_path_val = gdrive_path + 'data/Final_Validation.zip'\n",
    "    zip_path_test = gdrive_path + 'data/Final_Test.zip'\n",
    "    !unzip -q \"{zip_path_train}\"\n",
    "    !unzip -q \"{zip_path_val}\"\n",
    "    !unzip -q \"{zip_path_test}\"\n",
    "    \n",
    "    if HAS_GPU:\n",
    "        print(\"Using GPU\")\n",
    "else:\n",
    "    HAS_GPU = False\n",
    "    print(\"Using CPU\")\n",
    "    \n",
    "import utils.helpers as utils\n",
    "#import loader.gtsrb_data as dataset\n",
    "\n",
    "# If we run cuda then accomodate these datatypes.\n",
    "FloatTensor = torch.cuda.FloatTensor if HAS_GPU else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if HAS_GPU else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if HAS_GPU else torch.ByteTensor\n",
    "Tensor = FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "070a8a0d-345a-4418-89ba-cf282ca8adf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36m00000\u001b[m\u001b[m \u001b[1m\u001b[36m00004\u001b[m\u001b[m \u001b[1m\u001b[36m00008\u001b[m\u001b[m \u001b[1m\u001b[36m00012\u001b[m\u001b[m \u001b[1m\u001b[36m00016\u001b[m\u001b[m \u001b[1m\u001b[36m00020\u001b[m\u001b[m \u001b[1m\u001b[36m00024\u001b[m\u001b[m \u001b[1m\u001b[36m00028\u001b[m\u001b[m \u001b[1m\u001b[36m00032\u001b[m\u001b[m \u001b[1m\u001b[36m00036\u001b[m\u001b[m \u001b[1m\u001b[36m00040\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36m00001\u001b[m\u001b[m \u001b[1m\u001b[36m00005\u001b[m\u001b[m \u001b[1m\u001b[36m00009\u001b[m\u001b[m \u001b[1m\u001b[36m00013\u001b[m\u001b[m \u001b[1m\u001b[36m00017\u001b[m\u001b[m \u001b[1m\u001b[36m00021\u001b[m\u001b[m \u001b[1m\u001b[36m00025\u001b[m\u001b[m \u001b[1m\u001b[36m00029\u001b[m\u001b[m \u001b[1m\u001b[36m00033\u001b[m\u001b[m \u001b[1m\u001b[36m00037\u001b[m\u001b[m \u001b[1m\u001b[36m00041\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36m00002\u001b[m\u001b[m \u001b[1m\u001b[36m00006\u001b[m\u001b[m \u001b[1m\u001b[36m00010\u001b[m\u001b[m \u001b[1m\u001b[36m00014\u001b[m\u001b[m \u001b[1m\u001b[36m00018\u001b[m\u001b[m \u001b[1m\u001b[36m00022\u001b[m\u001b[m \u001b[1m\u001b[36m00026\u001b[m\u001b[m \u001b[1m\u001b[36m00030\u001b[m\u001b[m \u001b[1m\u001b[36m00034\u001b[m\u001b[m \u001b[1m\u001b[36m00038\u001b[m\u001b[m \u001b[1m\u001b[36m00042\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36m00003\u001b[m\u001b[m \u001b[1m\u001b[36m00007\u001b[m\u001b[m \u001b[1m\u001b[36m00011\u001b[m\u001b[m \u001b[1m\u001b[36m00015\u001b[m\u001b[m \u001b[1m\u001b[36m00019\u001b[m\u001b[m \u001b[1m\u001b[36m00023\u001b[m\u001b[m \u001b[1m\u001b[36m00027\u001b[m\u001b[m \u001b[1m\u001b[36m00031\u001b[m\u001b[m \u001b[1m\u001b[36m00035\u001b[m\u001b[m \u001b[1m\u001b[36m00039\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "if COLAB:\n",
    "  !ls /content/Final_Training/Images\n",
    "else:\n",
    "  !ls data/Final_Training/Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8abfcf83-83fa-4236-81a1-0e92d4d89196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import loader.args as load_args\n",
    "args = load_args.get_args(is_local)\n",
    "\n",
    "TRAIN_DATA_PATH = args.data_dir_train\n",
    "VAL_DATA_PATH = args.data_dir_val\n",
    "TEST_DATA_PATH = args.data_dir_test\n",
    "BATCH_SIZE = args.batch_size\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = args.batch_size\n",
    "LEARNING_RATE = args.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abff6254-15ea-4d9c-88f9-aa442cbba976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader import transforms as tfs\n",
    "    # NO augmentation--> train=39209, test=12630, val=3870.\n",
    "\n",
    "train_data = datasets.ImageFolder(\n",
    "    root=TRAIN_DATA_PATH, \n",
    "    transform=tfs.base_transform)\n",
    "train_loader = data.DataLoader(train_data, \n",
    "    batch_size=BATCH_SIZE, shuffle=True,  \n",
    "    num_workers=2)\n",
    "\n",
    "test_data = datasets.ImageFolder(\n",
    "    root=TEST_DATA_PATH, \n",
    "    transform=tfs.base_transform)\n",
    "test_loader  = data.DataLoader(test_data, \n",
    "    batch_size=BATCH_SIZE, shuffle=True, \n",
    "    num_workers=2)\n",
    "\n",
    "val_data = datasets.ImageFolder(\n",
    "    root=VAL_DATA_PATH, \n",
    "    transform=tfs.base_transform)\n",
    "val_loader  = data.DataLoader(test_data, \n",
    "    batch_size=BATCH_SIZE, shuffle=False, \n",
    "    num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21383d32-698e-442c-95d6-ae15ac5476bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unaugmented dataset: 39250 training samples & 12650 validation samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Unaugmented dataset: %d training samples & %d validation samples\\n' % (\n",
    "len(train_loader)*args.batch_size, len(val_loader)*args.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef4c9c6-7229-412b-9000-d481c65d6505",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.models import Net1\n",
    "\n",
    "model = Net1()\n",
    "if HAS_GPU:\n",
    "    model.cuda()\n",
    "\n",
    "# Optimizer is updated to *not* include non-gradient weights.    \n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                                                      lr=args.learning_rate)\n",
    "# Reduce learning rate when a metric has stopped improving. \n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',\n",
    "                                                 patience=5,\n",
    "                                                 factor=0.5,\n",
    "                                                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f585db72-db78-4fee-b18a-67aaef33de9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 26, 26]           1,184\n",
      "         MaxPool2d-2            [-1, 8, 13, 13]               0\n",
      "              ReLU-3            [-1, 8, 13, 13]               0\n",
      "            Conv2d-4             [-1, 10, 9, 9]           2,010\n",
      "         MaxPool2d-5             [-1, 10, 4, 4]               0\n",
      "              ReLU-6             [-1, 10, 4, 4]               0\n",
      "            Linear-7                   [-1, 32]           5,152\n",
      "              ReLU-8                   [-1, 32]               0\n",
      "            Linear-9                    [-1, 6]             198\n",
      "           Conv2d-10          [-1, 100, 28, 28]           7,600\n",
      "      BatchNorm2d-11          [-1, 100, 14, 14]             200\n",
      "        Dropout2d-12          [-1, 100, 14, 14]               0\n",
      "           Conv2d-13          [-1, 150, 12, 12]         135,150\n",
      "      BatchNorm2d-14            [-1, 150, 6, 6]             300\n",
      "        Dropout2d-15            [-1, 150, 6, 6]               0\n",
      "           Conv2d-16            [-1, 250, 4, 4]         337,750\n",
      "      BatchNorm2d-17            [-1, 250, 2, 2]             500\n",
      "        Dropout2d-18            [-1, 250, 2, 2]               0\n",
      "           Linear-19                  [-1, 350]         350,350\n",
      "           Linear-20                   [-1, 43]          15,093\n",
      "================================================================\n",
      "Total params: 855,487\n",
      "Trainable params: 855,487\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.26\n",
      "Params size (MB): 3.26\n",
      "Estimated Total Size (MB): 4.54\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c05cef4-43cc-43af-b82b-59fdbbcf365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.meter import AvgMeter, calc_accuracy\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "def train(epoch):\n",
    "    print('Epoch {} -------------------------------------------------------->'.format(epoch) )\n",
    "    print()\n",
    "    losses = AvgMeter()\n",
    "    accuracies = AvgMeter()\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    training_loss = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        if HAS_GPU:\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        \n",
    "        losses.update(loss.item(), data.size(0))\n",
    "        accuracy = calc_accuracy(output, target)[0]\n",
    "        train_accuracies.append(int(accuracy))\n",
    "        accuracies.update(accuracy, data.size(0))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        max_index = output.max(dim = 1)[1] # _, predicted\n",
    "        correct += (max_index == target).sum()\n",
    "        training_loss += loss\n",
    "        \n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Training set: Average loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "            losses.avg, int(accuracies.sum/100), accuracies.count, accuracies.avg))\n",
    "    \n",
    "    return train_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "292c2c5e-2636-414b-bf0a-7a2f181e8b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "def validate(epoch):\n",
    "    losses = AvgMeter()\n",
    "    accuracies = AvgMeter()\n",
    "    error_cases = []\n",
    "    \n",
    "    model.eval() # changes the forward() behaviour of the module for val/test.\n",
    "    \n",
    "    with torch.no_grad(): # disable tracking of gradients in autograd.\n",
    "        for data, target in val_loader:\n",
    "            if HAS_GPU:\n",
    "                data = data.cuda()\n",
    "                target = target.cuda()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "\n",
    "            losses.update(loss.item(), data.size(0))\n",
    "            accuracy = calc_accuracy(output, target)[0]\n",
    "            val_accuracies.append(accuracy)\n",
    "            accuracies.update(accuracy, data.size(0))\n",
    "\n",
    "            _, pred = output.topk(1, 1, True, True)\n",
    "            pred = pred.t()\n",
    "\n",
    "        print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "            losses.avg, int(accuracies.sum/100), accuracies.count, accuracies.avg))\n",
    "\n",
    "    return val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddafcd9-6772-4350-afb8-f25e638968ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 -------------------------------------------------------->\n",
      "\n",
      "Training set: Average loss: 3.9154, Accuracy: 2/50 (4.000%)\n",
      "\n",
      "Training set: Average loss: 3.5809, Accuracy: 397/5050 (7.861%)\n",
      "\n",
      "Training set: Average loss: 3.3679, Accuracy: 1314/10050 (13.075%)\n",
      "\n",
      "Training set: Average loss: 3.1832, Accuracy: 2603/15050 (17.296%)\n",
      "\n",
      "Training set: Average loss: 3.0023, Accuracy: 4285/20050 (21.372%)\n",
      "\n",
      "Training set: Average loss: 2.8333, Accuracy: 6302/25050 (25.158%)\n",
      "\n",
      "Training set: Average loss: 2.6767, Accuracy: 8642/30050 (28.759%)\n",
      "\n",
      "Training set: Average loss: 2.5248, Accuracy: 11318/35050 (32.291%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: dlopen(/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/image.so, 0x0006): symbol not found in flat namespace '__ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: dlopen(/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/image.so, 0x0006): symbol not found in flat namespace '__ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: dlopen(/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/image.so, 0x0006): symbol not found in flat namespace '__ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: dlopen(/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/image.so, 0x0006): symbol not found in flat namespace '__ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: nan, Accuracy: 12630/12630 (100.00%)\n",
      "\n",
      "Epoch 2 -------------------------------------------------------->\n",
      "\n",
      "Training set: Average loss: 1.3440, Accuracy: 33/50 (66.000%)\n",
      "\n",
      "Training set: Average loss: 1.2105, Accuracy: 3298/5050 (65.307%)\n",
      "\n",
      "Training set: Average loss: 1.1392, Accuracy: 6773/10050 (67.393%)\n",
      "\n",
      "Training set: Average loss: 1.0539, Accuracy: 10574/15050 (70.259%)\n",
      "\n",
      "Training set: Average loss: 0.9782, Accuracy: 14543/20050 (72.534%)\n",
      "\n",
      "Training set: Average loss: 0.9184, Accuracy: 18618/25050 (74.323%)\n",
      "\n",
      "Training set: Average loss: 0.8656, Accuracy: 22801/30050 (75.877%)\n",
      "\n",
      "Training set: Average loss: 0.8138, Accuracy: 27128/35050 (77.398%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: dlopen(/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/image.so, 0x0006): symbol not found in flat namespace '__ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: dlopen(/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/image.so, 0x0006): symbol not found in flat namespace '__ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: dlopen(/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/image.so, 0x0006): symbol not found in flat namespace '__ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: dlopen(/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/image.so, 0x0006): symbol not found in flat namespace '__ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: nan, Accuracy: 12630/12630 (100.00%)\n",
      "\n",
      "Epoch 3 -------------------------------------------------------->\n",
      "\n",
      "Training set: Average loss: 0.3139, Accuracy: 46/50 (92.000%)\n",
      "\n",
      "Training set: Average loss: 0.4043, Accuracy: 4518/5050 (89.465%)\n",
      "\n",
      "Training set: Average loss: 0.3973, Accuracy: 8995/10050 (89.502%)\n",
      "\n",
      "Training set: Average loss: 0.3709, Accuracy: 13585/15050 (90.266%)\n",
      "\n",
      "Training set: Average loss: 0.3569, Accuracy: 18177/20050 (90.658%)\n",
      "\n",
      "Training set: Average loss: 0.3397, Accuracy: 22829/25050 (91.134%)\n",
      "\n",
      "Training set: Average loss: 0.3248, Accuracy: 27479/30050 (91.444%)\n",
      "\n",
      "Training set: Average loss: 0.3143, Accuracy: 32150/35050 (91.726%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: dlopen(/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/image.so, 0x0006): symbol not found in flat namespace '__ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: dlopen(/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/image.so, 0x0006): symbol not found in flat namespace '__ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: dlopen(/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/image.so, 0x0006): symbol not found in flat namespace '__ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: dlopen(/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torchvision/image.so, 0x0006): symbol not found in flat namespace '__ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE'\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: nan, Accuracy: 12630/12630 (100.00%)\n",
      "\n",
      "Epoch 4 -------------------------------------------------------->\n",
      "\n",
      "Training set: Average loss: 0.2616, Accuracy: 45/50 (90.000%)\n",
      "\n",
      "Training set: Average loss: 0.2066, Accuracy: 4793/5050 (94.911%)\n",
      "\n",
      "Training set: Average loss: 0.1974, Accuracy: 9550/10050 (95.025%)\n",
      "\n",
      "Training set: Average loss: 0.1957, Accuracy: 14314/15050 (95.110%)\n",
      "\n",
      "Training set: Average loss: 0.1898, Accuracy: 19106/20050 (95.292%)\n",
      "\n",
      "Training set: Average loss: 0.1851, Accuracy: 23886/25050 (95.353%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_accuracy = []\n",
    "validation_accuracy = []\n",
    "\n",
    "for epoch in range(1, args.num_epochs + 1):\n",
    "    training_accuracy.append(train(epoch))\n",
    "    validation_accuracy.append(validate(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c5c7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot accuracy\n",
    "\n",
    "plt.plot(training_accuracy[4],'-o')\n",
    "plt.plot(validation_accuracy[4],'-o')\n",
    "plt.xlabel('Sample # per Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train','Valid'])\n",
    "plt.title('Train vs Valid Accuracy per Epoch (Best)')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3efedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = None\n",
    "val_loader = None\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    " torch.utils.data.ConcatDataset([datasets.ImageFolder(\n",
    "                                    TRAIN_DATA_PATH, \n",
    "                                    transform=tfs.base_transform),\n",
    "                               datasets.ImageFolder(\n",
    "                                    TRAIN_DATA_PATH,\n",
    "                                    transform=tfs.data_translate),\n",
    "                               datasets.ImageFolder(\n",
    "                                    TRAIN_DATA_PATH,\n",
    "                                    transform=tfs.data_grayscale),\n",
    "                               datasets.ImageFolder(\n",
    "                                    TRAIN_DATA_PATH,\n",
    "                                    transform=tfs.data_center),\n",
    "                               datasets.ImageFolder(\n",
    "                                    TRAIN_DATA_PATH,\n",
    "                                    transform=tfs.data_rotate),\n",
    "                               datasets.ImageFolder(\n",
    "                                    TRAIN_DATA_PATH,\n",
    "                                    transform=tfs.data_jitter_hue)]), \n",
    "                                    batch_size=args.batch_size, \n",
    "                                    shuffle=True, num_workers=2, \n",
    "                                    pin_memory=HAS_GPU)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    " torch.utils.data.ConcatDataset([datasets.ImageFolder(\n",
    "                                    VAL_DATA_PATH, \n",
    "                                    transform=tfs.base_transform),\n",
    "                               datasets.ImageFolder(\n",
    "                                    VAL_DATA_PATH,\n",
    "                                    transform=tfs.data_translate),\n",
    "                               datasets.ImageFolder(\n",
    "                                    VAL_DATA_PATH,\n",
    "                                    transform=tfs.data_grayscale),\n",
    "                               datasets.ImageFolder(\n",
    "                                    VAL_DATA_PATH,\n",
    "                                    transform=tfs.data_center),\n",
    "                               datasets.ImageFolder(\n",
    "                                    VAL_DATA_PATH,\n",
    "                                    transform=tfs.data_rotate),\n",
    "                               datasets.ImageFolder(\n",
    "                                    VAL_DATA_PATH,\n",
    "                                    transform=tfs.data_jitter_hue)]), \n",
    "                                    batch_size=args.batch_size, \n",
    "                                    shuffle=False, num_workers=2, \n",
    "                                    pin_memory=HAS_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a228991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Augmented dataset: %d training samples & %d validation samples\\n' % (\n",
    "    len(train_loader.dataset), len(val_loader.dataset)))\n",
    "\n",
    "# Get labels from concatenated datasets.\n",
    "train_dataset_list = train_loader.dataset.datasets\n",
    "train_concat_labels = []\n",
    "for ds in train_dataset_list:\n",
    "    train_concat_labels.extend(ds.targets)\n",
    "\n",
    "val_dataset_list = val_loader.dataset.datasets\n",
    "val_concat_labels = [\n",
    "for ds in val_dataset_list:\n",
    "    val_concat_labels.extend(ds.targets)\n",
    "\n",
    "class_labels = range(43)\n",
    "\n",
    "print('Distribution of classes in augmented train dataset:')\n",
    "fig, ax = plt.subplots()\n",
    "_, counts = np.unique(train_concat_labels, return_counts=True)\n",
    "ax.bar(class_labels, counts)\n",
    "ax.set_xticks(class_labels, minor=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34377311",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "\n",
    "model = Net1()\n",
    "if HAS_GPU:\n",
    "    model.cuda()\n",
    "\n",
    "# Optimizer is updated to *not* include non-gradient weights.    \n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                                                      lr=args.learning_rate)\n",
    "# Reduce learning rate when a metric has stopped improving. \n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',\n",
    "                                                 patience=5,\n",
    "                                                 factor=0.5,\n",
    "                                                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb38f062",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = []\n",
    "validation_accuracy = []\n",
    "\n",
    "for epoch in range(1, args.num_epochs + 1):\n",
    "    training_accuracy.append(train(epoch))\n",
    "    validation_accuracy.append(validate(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ee3b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot accuracy\n",
    "\n",
    "plt.plot(training_accuracy[4],'-o')\n",
    "plt.plot(validation_accuracy[4],'-o')\n",
    "plt.xlabel('Sample # per Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train','Valid'])\n",
    "plt.title('Train vs Valid Accuracy per Epoch (Best)')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275e60c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86036ca5-87b9-4e5d-ac54-f7aa79039219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88ca5bc-a7f8-40e1-a64a-89f5f2f5f3a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf76ad96-99c8-4b09-ae28-9e75258630c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871b4e85-0c8c-4ebe-8185-ff2189e2a975",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    train_data        = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, \n",
    "                                                         transform=tfs.data_transforms)\n",
    "    train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)\n",
    "    test_data         = torchvision.datasets.ImageFolder(root=TEST_DATA_PATH, \n",
    "                                                         transform=tfs.data_transforms)\n",
    "    test_loader  = data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_data          = torchvision.datasets.ImageFolder(root=VAL_DATA_PATH, \n",
    "                                                         transform=tfs.data_transforms)\n",
    "    val_loader   = data.DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)\n",
    "    \n",
    "    \n",
    "ds = datasets.ImageFolder(VAL_DATA_PATH, transform=None)\n",
    "#dir(ds)\n",
    "#ds.samples[0:5] # the first five samples\n",
    "#ds.imgs[33] # img 33\n",
    "#ds.samples[33] # sample 33, equivalent of previous line\n",
    "#ds.samples[33][0] # a sample path\n",
    "#ds.samples[33][1] # a sample class label\n",
    "#ds.find_classes(VAL_DATA_PATH)\n",
    "#ds.targets\n",
    "\n",
    "\n",
    "def validation():\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in val_loader:\n",
    "        with torch.no_grad():\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            if HAS_GPU:\n",
    "                data = data.cuda()\n",
    "                target = target.cuda()\n",
    "            output = model(data)\n",
    "            validation_loss += F.nll_loss(output, target, size_average=False).data.item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    validation_loss /= len(val_loader.dataset)\n",
    "    scheduler.step(np.around(validation_loss,2))\n",
    "    \n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        validation_loss, correct, len(val_loader.dataset),\n",
    "        100. * correct / len(val_loader.dataset))) \n",
    "        \n",
    "        \n",
    "def train(epoch):\n",
    "    losses = AvgMeter()\n",
    "    accuracies = AvgMeter()\n",
    "    \n",
    "    model.train()\n",
    "    correct = 0\n",
    "    training_loss = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        if HAS_GPU:\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        \n",
    "        #losses.update(loss.item(), data.size(0))\n",
    "        #accuracy = calc_accuracy(output, target)[0]\n",
    "        #accuracies.update(accuracy, data.size(0))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        max_index = output.max(dim = 1)[1] # _, predicted\n",
    "        correct += (max_index == target).sum()\n",
    "        training_loss += loss\n",
    "        \n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            train_loss=training_loss / len(train_loader.dataset)\n",
    "            accu = 100. * correct / len(train_loader.dataset)\n",
    "            print('Train Loss: %.3f | Accuracy: %.3f'%(train_loss,accu))\n",
    "            print('---------------------------------------------------')\n",
    "            print('Epoch: {} [{}/{} ({:.0f}%)]\\tLoss per example: {:.6f}\\tLoss: {:.6f}'.format(\n",
    "                        epoch, \n",
    "                        batch_idx * len(data), # this batch number, times total length\n",
    "                        len(train_loader.dataset), # length of the entire dataset.\n",
    "                        100. * batch_idx / len(train_loader), \n",
    "                        loss.data.item()/(args.batch_size * args.log_interval),\n",
    "                        loss.data.item()) )\n",
    "            \n",
    "    train_accu.append(accu.detach().cpu().numpy())\n",
    "    train_losses.append(train_loss.detach().cpu().numpy())\n",
    "    \n",
    "    \n",
    "def validation():\n",
    "    eval_losses=[]\n",
    "    eval_accu_ls=[]\n",
    "\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in val_loader:\n",
    "        with torch.no_grad():\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            if HAS_GPU:\n",
    "                data = data.cuda()\n",
    "                target = target.cuda()\n",
    "            output = model(data)\n",
    "             # sum up batch loss\n",
    "            validation_loss += F.nll_loss(output, \n",
    "                                          target, \n",
    "                                          size_average=False).data.item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "        validation_loss /= len(val_loader.dataset)\n",
    "        scheduler.step(np.around(validation_loss,2))\n",
    "\n",
    "        eval_loss=validation_loss / len(val_loader.dataset)\n",
    "        eval_accu = 100. * correct / len(val_loader.dataset)\n",
    "\n",
    "    eval_losses.append(eval_loss.detach().cpu().numpy())\n",
    "    eval_accu_ls.append(eval_accu.detach().cpu().numpy())\n",
    "\n",
    "    print('Validation Loss: %.3f | Accuracy: %.3f'%(test_loss,accu)) \n",
    "\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        validation_loss, \n",
    "        correct, \n",
    "        len(val_loader.dataset),\n",
    "        100. * correct / len(val_loader.dataset))\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
